{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb09f6f1",
   "metadata": {},
   "source": [
    "## Unzip, read sound files, convert to image, store in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2156d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run once to unpack\n",
    "# !unzip ./data/archive.zip -d ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321c3305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: librosa in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (4.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from librosa) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdbe5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48baf343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\root\\AppData\\Local\\Temp\\ipykernel_26512\\2361651441.py\", line 14, in <module>\n",
      "    import torchvision.transforms as transforms\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torchvision\\__init__.py\", line 6, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torchvision\\models\\__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torchvision\\models\\convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torchvision\\ops\\__init__.py\", line 23, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torchvision\\ops\\poolers.py\", line 10, in <module>\n",
      "    from .roi_align import roi_align\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torchvision\\ops\\roi_align.py\", line 4, in <module>\n",
      "    import torch._dynamo\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 64, in <module>\n",
      "    torch.manual_seed = disable(torch.manual_seed)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\decorators.py\", line 50, in disable\n",
      "    return DisableContext()(fn)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 410, in __call__\n",
      "    (filename is None or trace_rules.check(fn))\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3378, in check\n",
      "    return check_verbose(obj, is_inlined_call).skipped\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3361, in check_verbose\n",
      "    rule = torch._dynamo.trace_rules.lookup_inner(\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3442, in lookup_inner\n",
      "    rule = get_torch_obj_rule_map().get(obj, None)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2782, in get_torch_obj_rule_map\n",
      "    obj = load_object(k)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2811, in load_object\n",
      "    val = _load_obj_from_str(x[0])\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2795, in _load_obj_from_str\n",
      "    return getattr(importlib.import_module(module), obj_name)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py\", line 417, in <module>\n",
      "    values=torch.randn(3, 3, device=\"meta\"),\n",
      "c:\\Users\\root\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py:417: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  values=torch.randn(3, 3, device=\"meta\"),\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7e4e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train_test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05314eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test_cat</th>\n",
       "      <th>test_dog</th>\n",
       "      <th>train_cat</th>\n",
       "      <th>train_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cat_22.wav</td>\n",
       "      <td>dog_barking_97.wav</td>\n",
       "      <td>cat_99.wav</td>\n",
       "      <td>dog_barking_33.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cat_116.wav</td>\n",
       "      <td>dog_barking_0.wav</td>\n",
       "      <td>cat_54.wav</td>\n",
       "      <td>dog_barking_86.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cat_155.wav</td>\n",
       "      <td>dog_barking_93.wav</td>\n",
       "      <td>cat_34.wav</td>\n",
       "      <td>dog_barking_45.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cat_58.wav</td>\n",
       "      <td>dog_barking_10.wav</td>\n",
       "      <td>cat_132.wav</td>\n",
       "      <td>dog_barking_76.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cat_77.wav</td>\n",
       "      <td>dog_barking_26.wav</td>\n",
       "      <td>cat_124.wav</td>\n",
       "      <td>dog_barking_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_15.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_88.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_73.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_32.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_113.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     test_cat            test_dog    train_cat  \\\n",
       "0             0   cat_22.wav  dog_barking_97.wav   cat_99.wav   \n",
       "1             1  cat_116.wav   dog_barking_0.wav   cat_54.wav   \n",
       "2             2  cat_155.wav  dog_barking_93.wav   cat_34.wav   \n",
       "3             3   cat_58.wav  dog_barking_10.wav  cat_132.wav   \n",
       "4             4   cat_77.wav  dog_barking_26.wav  cat_124.wav   \n",
       "..          ...          ...                 ...          ...   \n",
       "110         110          NaN                 NaN   cat_15.wav   \n",
       "111         111          NaN                 NaN   cat_88.wav   \n",
       "112         112          NaN                 NaN   cat_73.wav   \n",
       "113         113          NaN                 NaN   cat_32.wav   \n",
       "114         114          NaN                 NaN  cat_113.wav   \n",
       "\n",
       "              train_dog  \n",
       "0    dog_barking_33.wav  \n",
       "1    dog_barking_86.wav  \n",
       "2    dog_barking_45.wav  \n",
       "3    dog_barking_76.wav  \n",
       "4     dog_barking_4.wav  \n",
       "..                  ...  \n",
       "110                 NaN  \n",
       "111                 NaN  \n",
       "112                 NaN  \n",
       "113                 NaN  \n",
       "114                 NaN  \n",
       "\n",
       "[115 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92ea4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make new folder to relocate image data\n",
    "!mkdir -p img_dataset/train/{cat,dog}\n",
    "!mkdir -p img_dataset/test/{cat,dog}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1075c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectogram(audio_file_name,source_path,save_path): \n",
    "    x, sr = librosa.load(source_path+audio_file_name)\n",
    "    X = librosa.stft(x)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    librosa.display.specshow(Xdb, sr=sr, y_axis='hz')\n",
    "    plt.ylabel('')\n",
    "    plt.axis('off')\n",
    "    file_name = audio_file_name.replace('.wav','')\n",
    "    plt.savefig(save_path+file_name+'.jpg', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close() # Comment if you want to see the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649413b8",
   "metadata": {},
   "source": [
    "## Image Process one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a23ef796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert wav to image\n",
    "\n",
    "# source sound file, file directory of sound file, destination for image\n",
    "\n",
    "create_spectogram('cat_1.wav','./data/cats_dogs/train/cat/','./img_dataset/train/cat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07ec49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a PIL image\n",
    "image = Image.open('./img_dataset/train/cat/cat_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "634eef79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 59,  59,  59,  ...,  59,  59,  59],\n",
      "         [ 59,  59,  59,  ...,  59,  59,  59],\n",
      "         [ 59,  59,  59,  ...,  59,  59,  59],\n",
      "         ...,\n",
      "         [191, 214, 216,  ..., 210, 206, 187],\n",
      "         [187, 205, 213,  ..., 179, 197, 206],\n",
      "         [174, 164, 149,  ..., 184, 164, 190]],\n",
      "\n",
      "        [[ 76,  76,  76,  ...,  76,  76,  76],\n",
      "         [ 76,  76,  76,  ...,  76,  76,  76],\n",
      "         [ 76,  76,  76,  ...,  76,  76,  76],\n",
      "         ...,\n",
      "         [210, 214, 218,  ..., 215, 201, 187],\n",
      "         [217, 217, 223,  ..., 192, 200, 213],\n",
      "         [212, 181, 162,  ..., 201, 169, 199]],\n",
      "\n",
      "        [[192, 192, 192,  ..., 192, 192, 192],\n",
      "         [192, 192, 192,  ..., 192, 192, 192],\n",
      "         [192, 192, 192,  ..., 192, 192, 192],\n",
      "         ...,\n",
      "         [241, 228, 229,  ..., 241, 225, 209],\n",
      "         [241, 226, 237,  ..., 219, 219, 218],\n",
      "         [250, 210, 204,  ..., 252, 211, 216]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# Create the spectogram images:\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Resize(size = (256,256))\n",
    "])\n",
    "  \n",
    "# transform = transforms.PILToTensor()\n",
    "# Convert the PIL image to Torch tensor\n",
    "img_tensor = transform(image)\n",
    "  \n",
    "# print the converted Torch tensor\n",
    "print(img_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ace90",
   "metadata": {},
   "source": [
    "## Bulk Process Wav to Images for Cat/Dogs and Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19541978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CAT_TRAIN = './data/cats_dogs/train/cat/' \n",
    "for sound in os.listdir(CAT_TRAIN): \n",
    "    create_spectogram(sound,CAT_TRAIN,'./img_dataset/train/cat/')\n",
    "    \n",
    "DOG_TRAIN = './data/cats_dogs/train/dog/' \n",
    "for sound in os.listdir(DOG_TRAIN): \n",
    "    create_spectogram(sound,DOG_TRAIN,'./img_dataset/train/dog/')\n",
    "    \n",
    "DOG_TEST = './data/cats_dogs/test/test/' \n",
    "for sound in os.listdir(DOG_TEST): \n",
    "    create_spectogram(sound,DOG_TEST,'./img_dataset/test/dog/')\n",
    "    \n",
    "    \n",
    "CAT_TEST = './data/cats_dogs/test/cats/' \n",
    "for sound in os.listdir(CAT_TEST): \n",
    "    create_spectogram(sound,CAT_TEST,'./img_dataset/test/cat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd780500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Illegal Audio-MPEG-Header 0x4c495354 at offset 38626.\n",
      "Note: Trying to resync...\n",
      "Note: Hit end of (available) data during resync.\n"
     ]
    }
   ],
   "source": [
    "Inferences = './data/cats_dogs/inferences/' \n",
    "for sound in os.listdir(Inferences): \n",
    "    create_spectogram(sound,Inferences,'./img_dataset/inferences/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24695226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Metadata for Tensor.Dataset\n",
    "\n",
    "image_names_ls = []\n",
    "file_location = []\n",
    "\n",
    "for i in ['test','train']:\n",
    "    file_location_subset = []\n",
    "    for j in ['cat','dog']:\n",
    "        image_names_ls.append([img for img in os.listdir(f'./img_dataset/{i}/{j}/')])\n",
    "        file_location.append([f'./img_dataset/{i}/{j}/{img}' for img in os.listdir(f'./img_dataset/{i}/{j}/')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12f1de5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set = pd.DataFrame({'image_name': image_names_ls[0] + image_names_ls[1], 'image_location': file_location[0] + file_location[1], 'target':len(file_location[0])*['cat']+len(file_location[1])*['dog']} )\n",
    "train_set = pd.DataFrame({'image_name': image_names_ls[2] + image_names_ls[3], 'image_location': file_location[2] + file_location[3], 'target':len(file_location[2])*['cat']+len(file_location[3])*['dog']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6417466",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat_28.jpg</td>\n",
       "      <td>./img_dataset/test/cat/cat_28.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat_82.jpg</td>\n",
       "      <td>./img_dataset/test/cat/cat_82.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat_55.jpg</td>\n",
       "      <td>./img_dataset/test/cat/cat_55.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat_110.jpg</td>\n",
       "      <td>./img_dataset/test/cat/cat_110.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat_20.jpg</td>\n",
       "      <td>./img_dataset/test/cat/cat_20.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name                      image_location\n",
       "0   cat_28.jpg   ./img_dataset/test/cat/cat_28.jpg\n",
       "1   cat_82.jpg   ./img_dataset/test/cat/cat_82.jpg\n",
       "2   cat_55.jpg   ./img_dataset/test/cat/cat_55.jpg\n",
       "3  cat_110.jpg  ./img_dataset/test/cat/cat_110.jpg\n",
       "4   cat_20.jpg   ./img_dataset/test/cat/cat_20.jpg"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfa25288",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('./img_dataset/test/test.csv')\n",
    "train_set.to_csv('./img_dataset/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f354f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48ae361e",
   "metadata": {},
   "source": [
    "# Research/References\n",
    "1. Data Source: https://www.kaggle.com/datasets/mmoreaux/audio-cats-and-dogs?select=cats_dogs\n",
    "2. Samples\n",
    "    - https://www.kaggle.com/code/thanht02/audio-classification-cnn-864d1f\n",
    "    - https://www.kaggle.com/code/kanncaa1/pytorch-tutorial-for-deep-learning-lovers\n",
    "3. Papers\n",
    "    - \n",
    "4. Data Loader\n",
    "    - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "    - https://www.kaggle.com/code/pinocookie/pytorch-dataset-and-dataloader\n",
    "5. Image Processing\n",
    "    - https://www.geeksforgeeks.org/converting-an-image-to-a-torch-tensor-in-python/\n",
    "    - https://www.tutorialspoint.com/pytorch-how-to-resize-an-image-to-a-given-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d604d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
